{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ce45e-a4b2-4f6f-8876-41be84b9a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Requests\n",
    "import pprint\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Data Science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Geocoding\n",
    "from api_keys import opencage_key\n",
    "from api_keys import geoapify_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1ebf2-5167-49d7-8bfc-3b20a1a1c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file path\n",
    "filepath_cards = \"../Resources/cards_data.csv\"\n",
    "filepath_users = \"../Resources/users_data.csv\"\n",
    "# Read in the data.\n",
    "df_cards = pd.read_csv(filepath_cards)\n",
    "df_users = pd.read_csv(filepath_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1661b-45f5-47f1-a93e-5b51826870af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards.info()\n",
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f5b34-d5e3-4f2e-863d-febff6b588b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging noth files on ID column\n",
    "df = pd.merge(df_cards, df_users, left_on=\"client_id\", right_on=\"id\", how=\"inner\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23ef4c-d6f3-4699-869a-b35fb49d7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing dollar sign from monetary columlns\n",
    "df[\"credit_limit\"] = df.credit_limit.str.strip(\"$\")\n",
    "df[\"per_capita_income\"] = df.per_capita_income.str.strip(\"$\")\n",
    "df[\"yearly_income\"] = df.yearly_income.str.strip(\"$\")\n",
    "df[\"total_debt\"] = df.total_debt.str.strip(\"$\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4fd6f3-2745-4ee5-b09a-68e4ca2dee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting objects to int value\n",
    "df[\"credit_limit\"] = df[\"credit_limit\"].astype(int)\n",
    "df[\"per_capita_income\"] = df[\"per_capita_income\"].astype(int)\n",
    "df[\"yearly_income\"] = df[\"yearly_income\"].astype(int)\n",
    "df[\"total_debt\"] =df[\"total_debt\"].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5c88e-f7c2-49ed-880a-a9e3c4eb5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates by client_id\n",
    "df2 = df.drop_duplicates(subset='client_id', keep='first')\n",
    "\n",
    "# Checking the result after removing duplicates\n",
    "df2.head()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a787969-442b-4092-af03-1a4fc323e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "df2 = df2.drop(columns=['id_x', 'card_brand', 'card_type', 'card_number', 'expires', 'cvv', 'has_chip', 'num_cards_issued', 'credit_limit', 'acct_open_date', 'year_pin_last_changed', 'card_on_dark_web', 'id_y', 'retirement_age'])\n",
    "\n",
    "# Checking the result after dropping the columns\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f1dc8-c180-4211-9471-2863b503d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Debt to Income column\n",
    "\n",
    "df2['debt_to_income'] = df2['total_debt'] / df2['yearly_income']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c575535-5a90-4b7a-ae3e-a7b1334e4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reverse Geocode function\n",
    "def reverse_geocode(lat, lng, api_key):\n",
    "    base_url = \"https://api.opencagedata.com/geocode/v1/json\"\n",
    "    params = {\n",
    "        \"q\": f\"{lat},{lng}\",\n",
    "        \"key\": api_key,  # Using the API key passed from the imported file\n",
    "        \"language\": \"en\",\n",
    "        \"pretty\": 1\n",
    "    }\n",
    "    \n",
    "    # Make the API request\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Debugging: Print out the status and the response body\n",
    "    print(f\"Requesting coordinates: {lat}, {lng}\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Check if there are results\n",
    "        if data['results']:\n",
    "            print(f\"Address found: {data['results'][0]['formatted']}\")\n",
    "            return data['results'][0]['formatted']\n",
    "        else:\n",
    "            print(\"No results found.\")\n",
    "            return \"No results found\"\n",
    "    else:\n",
    "        # Print the error message and response\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)  # This will print the response text for error details\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "# Add a 1-second delay to avoid overloading the API\n",
    "def delayed_reverse_geocode(lat, lng, api_key):\n",
    "    time.sleep(1)  # Sleep for 1 second between requests\n",
    "    return reverse_geocode(lat, lng, api_key)\n",
    "\n",
    "# Loop the reverse goecode through each row\n",
    "df2['address'] = df2.apply(lambda row: delayed_reverse_geocode(row['latitude'], row['longitude'], opencage_key), axis=1)\n",
    "\n",
    "# Check the result\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b6a92-1e72-4f29-a2cb-e711cd9a0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full DataFrame to a new CSV file\n",
    "df2.to_csv('geocode_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f312b-b912-4124-9b1d-380133e64de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Create new dataframe\n",
    "df3 = df2.copy()\n",
    "\n",
    "# Define a pattern for state and zip code\n",
    "address_pattern = r'(\\w{2}) (\\d{5})'\n",
    "\n",
    "# Add a comma after the state abbreviation and before the zip code\n",
    "def add_comma(address):\n",
    "    # Search for the pattern of the state and zip code\n",
    "    match = re.search(address_pattern, address)\n",
    "    if match:\n",
    "        # If a match is found, reformat the address with a comma between state and zip code\n",
    "        state = match.group(1)\n",
    "        zip_code = match.group(2)\n",
    "        formatted_address = address.replace(f\"{state} {zip_code}\", f\"{state}, {zip_code}\")\n",
    "        return formatted_address\n",
    "    else:\n",
    "        # Return the original address if no match is found\n",
    "        return address\n",
    "\n",
    "# Apply the function to the 'address' column to create the new formatted address\n",
    "df3['address'] = df3['address'].apply(add_comma)\n",
    "\n",
    "# Check the result\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee23a5c-4332-49c1-b9dc-d5d91678af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the state abbreviation (two-letter state code)\n",
    "def extract_state(address):\n",
    "    # Regex pattern to capture the two-letter state abbreviation before the zip code\n",
    "    match = re.search(r'\\b([A-Z]{2})\\b,\\s*\\d{5}', address)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the state abbreviation\n",
    "    else:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "# Apply the function to the 'address' column to create the new 'state' column\n",
    "df3['state'] = df3['address'].apply(extract_state)\n",
    "\n",
    "# Reorder the columns to place 'state' directly to the right of 'address'\n",
    "cols = ['client_id', 'current_age', 'birth_year', 'birth_month', 'gender', 'address', 'state', 'latitude', 'longitude', \n",
    "        'per_capita_income', 'yearly_income', 'total_debt', 'credit_score', 'num_credit_cards', 'debt_to_income']\n",
    "\n",
    "df3 = df3[cols]\n",
    "\n",
    "# Check the result\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff74e5d-cfff-48d6-ac43-d8b8041a305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows where the 'state' column has null values\n",
    "null_state_rows = df3[df3['state'].isnull()]\n",
    "\n",
    "# Display the rows with null values in the 'state' column\n",
    "print(null_state_rows[['address', 'state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113dc9ee-c617-4291-ab74-096086ebe0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with null values in the 'state' column\n",
    "df3 = df3.dropna(subset=['state'])\n",
    "\n",
    "# Check the result\n",
    "df3.info()\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2e2ef-2385-4ac1-b05d-a4e8b07e6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full DataFrame to a new CSV file\n",
    "df3.to_csv('full_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd80e90-cf49-4209-b1ed-2afab52b68e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
